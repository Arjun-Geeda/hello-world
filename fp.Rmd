
title: "R Notebook"
output: html_notebook

Industry: Human Resource management
Challenge -
A company has been in industry since a long time. Their business had been increasing quite well over past, however in recent years, there has been a slowdown in terms of growth because their best and most experienced employees leaving prematurely. The VP of the firm is not very happy with the company's best and most experienced employees leaving prematurely. The VP of the firm has employed you to find out insights in the company employee data and find out an answer as to know why best and most experienced employees are leaving prematurely.
Solution -
As a first step the VP planned to know the useful insights out of the employee data available. Using R, he also wanted his team members to give him a forecast model to predict which employees could be leaving the company, as well as answer to why their best and most experienced employees are leaving prematurely. This will help him plan his next steps to avoid the churn out. He wanted a script that would contain the following:
. A visualization and distribution (of all the employee relative fields)
. Forecast using different machine learning models
. Comparison among different machine learning models and cross validating through them test and train set
. Find out why best and most experienced employees are leaving prematurely.
. Give a final prediction model to forecast
Actions to be Performed
. Set the Directory and load the dataset into R, verify that the data is loaded correctly
. For finding the insights out of our data several techniques can be used
o Find the correlation values of the attributes of our data
o Visualize the characteristics of the whole data and only the people who left, use plots and histograms
o Evaluate the values of each attributes for both left and non-left employees
o Analyse the department wise turnouts and find out the percentage of employees leaving from each department
. Build a classification model to forecast what are the attributes of people who leave the company
o Build models using Decision Tree, Random Forest, Naïve Bayes and SVM techniques and find out the most accurate one

#Introduction : 
####Problem Description : 
####Why are our best and most experienced employees leaving prematurely? Try to predict which valuable employees will leave next. Fields in the dataset include:
#### * Employee satisfaction level (satisfaction_level)
#### * Last evaluation (last_evaluation)
#### * Number of projects (number_project)
#### * Average monthly hours (average_montly_hours)
#### * Time spent at the company (time_spend_company)
#### * Whether they have had a work accident (Work_accident)
#### * Whether they have had a promotion in the last 5 years (promotion_last_5years)
#### * Sales (sales)
#### * Salary (salary)
#### * Whether the employee has left (left)



###Loading Libraries....
```{r , fig.width=4, fig.height=4}
library(lattice)  # Used for Data Visualization
require(caret)    # for data pre-processing
require(pROC)     # for ROC Curves
library(ipred)    # for bagging and  k fold cv
library(e1071)    # for SVM
library(ggplot2)  # for Plots
library(caret)    # for Splitting
library(pROC)     # for ROC curves
```

###Let us read the data
. Set the Directory and load the dataset into R, verify that the data is loaded correctly
```{r , fig.width=4, fig.height=4}
setwd("D:/r project/Project Final")
# Importing the dataset
data = read.csv('project.csv', stringsAsFactors=FALSE)
head(data)
summary(data)
```

###Convert department and salary to factor
```{r , fig.width=4, fig.height=4}
data$department<-as.factor(data$department)
data$salary<-as.factor(data$salary)
data$salary<-ordered(data$salary,levels=c("low","medium","high"))
```

##Data Visualization

###Finding the Correlation values and correlation plot for the values of the attributes of our data.

```{r , fig.width=4, fig.height=4}

library(corrplot)
M <-cor(data[,1:8])
corrplot( M , method="circle")

```


### Plotting some box plots

### Class 1 refers to people who left the company

```{r , fig.width=4, fig.height=4}
ggplot(data, aes(x =  salary, y = satisfaction_level, fill = factor(left), colour = factor(left))) + 
geom_boxplot(outlier.colour = "black") + xlab("Salary") + ylab("Satisfacion level") 

ggplot(data, aes(x =  salary, y = time_spend_company, fill = factor(left), colour = factor(left))) + 
geom_boxplot(outlier.colour = NA) + xlab("Salary") + ylab("time_spend_company") 

ggplot(data, aes(x =  factor(time_spend_company), y = average_montly_hours, fill = factor(left), colour = factor(left))) + 
  geom_boxplot(outlier.colour = NA) + xlab("Time spend Company") + ylab("Average Monthly Hours") 
hist(data$time_spend_company ,col="#3090C7", main = "Time spent in Company")
plot(data$department ,col="#3090C7",ylim = c(0,5000) , main = "Department")
hist(data$number_project,col="#3090C7",xlim = c(1,7),ylim = c(0,5000) ,xlab = "no. of projects",main = "No. of Projects done by each person")

```

#### Splitting the Data into the people who left and people who are still working

## Data frame of people who left the company
```{r , fig.width=4, fig.height=4}

hr_left<- subset(data, left=="1")
summary(hr_left[,1:8])

```

### Data frame of people who are still working in the company

```{r}

hr_notleft<- subset(data, left=="0")
summary(hr_notleft[,1:8])

```


### Plotting some box plots for people who left the company

```{r , fig.width=4, fig.height=6}

ggplot(hr_left, aes(x =  salary, y = satisfaction_level, fill = left, colour = left)) + 
geom_boxplot(outlier.colour = "black") + xlab("Salary") + ylab("Satisfacion level") 

ggplot(hr_left, aes(x =  salary, y = time_spend_company, fill = left, colour = left)) + 
geom_boxplot(outlier.colour = NA) + xlab("Salary") + ylab("time_spend_company") 

ggplot(hr_left, aes(x =  factor(time_spend_company), y = average_montly_hours, fill = left, colour = left)) + 
  geom_boxplot(outlier.colour = NA) + xlab("Time spend Company") + ylab("Average Monthly Hours") 

hist(hr_left$satisfaction_level,col="#3090C7", main = "Satisfaction level") 
hist(hr_left$last_evaluation,col="#3090C7", main = "Last evaluation")
hist(hr_left$average_montly_hours,col="#3090C7", main = "Average montly hours")
hist(hr_left$Work_accident,col="#3090C7", main = "Work accident")
barplot(table(hr_left$salary),col="#3090C7", main = "Salary")

```

### Plotting some box plots for people who have not left the company

```{r , fig.width=4, fig.height=6}
ggplot(hr_notleft, aes(x =  salary, y = satisfaction_level, fill = left, colour = left)) + 
geom_boxplot(outlier.colour = "black") + xlab("Salary") + ylab("Satisfacion level") 

ggplot(hr_notleft, aes(x =  salary, y = time_spend_company, fill = left, colour = left)) + 
geom_boxplot(outlier.colour = NA) + xlab("Salary") + ylab("time_spend_company") 

ggplot(hr_notleft, aes(x =  factor(time_spend_company), y = average_montly_hours, fill = left, colour = left)) + 
  geom_boxplot(outlier.colour = NA) + xlab("Time spend Company") + ylab("Average Monthly Hours") 

hist(hr_notleft$satisfaction_level,col="#3090C7", main = "Satisfaction level") 
hist(hr_notleft$last_evaluation,col="#3090C7", main = "Last evaluation")
hist(hr_notleft$average_montly_hours,col="#3090C7", main = "Average montly hours")
hist(hr_notleft$Work_accident,col="#3090C7", main = "Work accident")
barplot(table(hr_notleft$salary),col="#3090C7", main = "Salary")

```

###correlation plots for people who left
```{r}

summary(hr_left[,-c(7,9,10)])
D<-cor(hr_left[,-c(7,9,10)])
corrplot(D, method="circle")

```
###correlation plots for people who have not left
```{r}

summary(hr_notleft[,-c(7,9,10)])
E<-cor(hr_notleft[,-c(7,9,10)])
corrplot(E, method="circle")

```


###Analyse the department wise turnouts and find out the percentage of employees leaving from each department
```{r, fig.width=4, fig.height=4}
table(data$department)
table(hr_left$department)

# left<- data.select(sales,satisfaction_level,left)%>%group_by(department,left)
# summarize(n_left=n())
# hchart(left,"column",hcaes(x=sales,y=n_left,group=factor(left)))%>%hc_title(text="Departmentwise Attrition")
```



#Observations :
#### * Boxplot between Time Spent in Company and Salary :  In the dataset we find that the people leaving are more experienced (i.e. higher time spent in company on average) in the low and medium salary class.
#### * Boxplot between Satisfaction levels and Salary : In the dataset we find that the average satisfaction of the employees who left is lower than who haven't left
#### * Boxplot between Average Monthly Hours and Time spent Company: In the dataset we find that the people leaving have spent more hours at work

#Conclusion :
###Common traits of Good people leaving :
#### * Experienced                  
#### * Very low satisfaction levels                 
#### * Spend more time at work

###Possible Reasons for people leaving: 
#### * Experienced people may not be finding any challenges in work. Hence they leave.
#### * Work to Pay ratio may be high (because we find clear correlation only in low and medium salary ranges)



#Now let us predict who is leaving and who is not

###Splitting the data into training and test datasets

```{r , fig.width=4, fig.height=4}
library(caret)
set.seed(1234)
splitIndex <- createDataPartition(data$left, p = .80,list = FALSE, times = 1)
trainSplit <- data[ splitIndex,]
testSplit <- data[-splitIndex,]
print(table(trainSplit$left))
print(table(testSplit$left))

```

####Syntax for the cross validation and train routine in r :


#### Various options for the method parameter in train function :


### Now let's build a C5.0 tree 
```{r , fig.width=4, fig.height=4}
### re-train and predict
#trainControl(method , number). Method can be cv, repeatedcv, loocv, boot etc..
ctrl <- trainControl(method = "cv", number = 5)
tbmodel <- train(as.factor(left) ~., data = trainSplit, method = "C5.0Tree", trControl = ctrl)
#predict(predicted,test data)
pred <- predict(tbmodel, testSplit)
confusionMatrix(pred,testSplit$left)
```

####A few important terms :
#### * confusion matrix : In a confusion matrix each column of the matrix represents the instances in a predicted class while each row represents the instances in an actual class (or vice versa)
#### * Sensitivity (also called the true positive rate, the recall, or probability of detection[1] in some fields) measures the proportion of positives that are correctly identified as such (e.g., the percentage of sick people who are correctly identified as having the condition).
#### * Specificity (also called the true negative rate) measures the proportion of negatives that are correctly identified as such (e.g., the percentage of healthy people who are correctly identified as not having the condition).
#### * precision (also called positive predictive value) is the fraction of retrieved instances that are relevant.
#### * recall (also known as sensitivity) is the fraction of relevant instances that are retrieved.



#### * ROC : In statistics, a receiver operating characteristic (ROC), or ROC curve, is a graphical plot that illustrates the performance of a binary classifier system as its discrimination threshold is varied. The curve is created by plotting the true positive rate (TPR) against the false positive rate (FPR) at various threshold settings. The true-positive rate is also known as sensitivity, recall or probability of detection in machine learning. The false-positive rate is also known as the fall-out or probability of false alarm and can be calculated as (1 - specificity)


#### * Area under the ROC Curve (AUC) : When using normalized units, the area under the curve (often referred to as simply the AUC) is equal to the probability that a classifier will rank a randomly chosen positive instance higher than a randomly chosen negative one (assuming 'positive' ranks higher than 'negative'). The machine learning community most often uses the ROC AUC statistic for model comparison


```{r , fig.width=4, fig.height=4}
library(pROC)
# roc(testdata, prediction)
auc1 <- roc(as.numeric(testSplit$left), as.numeric(pred))
print(auc1)
plot(auc1, ylim=c(0,1), print.thres=TRUE, main=paste('AUC:',round(auc1$auc[[1]],3)),col = 'blue')
```



### SVM
```{r, fig.width=4, fig.height=4}
ctrl <- trainControl(method = "cv", number = 5)
modelsvm <- train(as.factor(left) ~., data = trainSplit, method = "svmLinear", trControl = ctrl)

### predict
predsvm <- predict(modelsvm,testSplit)
summary(predsvm)

### score prediction using AUC
confusionMatrix(predsvm,testSplit$left)
library(pROC)
aucsvm <- roc(as.numeric(testSplit$left), as.numeric(predsvm),  ci=TRUE)
plot(aucsvm, ylim=c(0,1), print.thres=TRUE, main=paste('SVM AUC:',round(aucsvm$auc[[1]],3)),col = 'blue')
```


### Random Forest
```{r, fig.width=4, fig.height=4}

library(randomForest)
modelrf <- randomForest(as.factor(left)~. , data = trainSplit)

importance(modelrf)

### predict
predrf <- predict(modelrf,testSplit)
summary(predrf)
### score prediction using AUC
confusionMatrix(predrf,testSplit$left)
library(pROC)
aucrf <- roc(as.numeric(testSplit$left), as.numeric(predrf),  ci=TRUE)
plot(aucrf, ylim=c(0,1), print.thres=TRUE, main=paste('Random Forest AUC:',round(aucrf$auc[[1]],3)),col = 'blue')
```


### decision tree
```{r, fig.width=4, fig.height=4}
library(rpart)					
					
modeldt <- rpart(formula = left ~ ., data = trainSplit, method = 'class')					
					
preddt <- predict(modeldt, testSplit, type = 'class')					
					
summary(preddt)
### score prediction using AUC
confusionMatrix(preddt,testSplit$left )
library(pROC)
aucdt <- roc(as.numeric(testSplit$left), as.numeric(predrf),  ci=TRUE)
plot(aucdt, ylim=c(0,1), print.thres=TRUE, main=paste('Decision Tree AUC:',round(aucrf$auc[[1]],3)),col = 'blue')
```

#### Naive bayes
```{r, fig.width=4, fig.height=4}

library(e1071)
library(rminer)
					
# 					
nbmodel <- naiveBayes(formula = as.factor(left) ~ ., data = trainSplit)	

predNB <- predict(nbmodel,testSplit, type = c("class", "raw"))					
# 				
summary(predNB)
# ### score prediction using AUC
confusionMatrix(predNB,testSplit$left)

library(pROC)
aucNB <- roc(as.numeric(testSplit$left), as.numeric(predrf),  ci=TRUE)
plot(aucNB, ylim=c(0,1), print.thres=TRUE, main=paste('Naive Bayes AUC:',round(aucrf$auc[[1]],3)),col = 'blue')
			
```



##Comparing all the ROC Curves
```{r , fig.width=10, fig.height=4}
library(ggplot2)
plot(aucrf, ylim=c(0,1), main=paste('ROC Comparison : 
RF(red),C5.0(black),Decision Tree(Green),SVM(Yellow), Naive Bayes(brown)'),col = 'red')
par(new = TRUE)
plot(auc1)
par(new = TRUE)
plot(aucsvm,col = "yellow")
par(new = TRUE)
plot(aucdt,col = "green")
par(new = TRUE)
plot(aucNB,col = "brown")
```

#### Sensitivity and Specificity values are the highest for random forest 
#### Clearly, we find Random Forest is performing well. Therefore, we'll continue ahead with Random Forest

### Feature Engineering

```{r , fig.width=4, fig.height=4}
# The importance routine in r for random forest models gives us the mean decrease gini value. Higher the Mean Decrease Gini value, more important the variable.
importance(modelrf)
```
#### Let's remove them least important variable and build the model with the remaining parameters and check the performance and repeat the process. Stop the process when there is a significant decrease in the performance measures

### Random Forest After Feature Engineering
```{r , fig.width=4, fig.height=4}
modelrf2 <- randomForest(as.factor(left) ~.-promotion_last_5years-Work_accident-salary-department , data = trainSplit)
importance(modelrf2)

### predict
predrf2 <- predict(modelrf2,testSplit)
summary(predrf2)

### score prediction using AUC
confusionMatrix(predrf2,testSplit$left)
library(pROC)
aucrf2 <- roc(as.numeric(testSplit$left), as.numeric(predrf2),  ci=TRUE)
plot(aucrf2, ylim=c(0,1), print.thres=TRUE, main=paste('Random Forest AUC:',round(aucrf2$auc[[1]],3)),col = 'blue')
```

#### * On observing the Mean Decrease Gini for each variable, we find variables 'promotion_last_5years', 'Work_accident', 'salary' and 'sales' are has the least value.
#### * So if we remove 'promotion_last_5years', 'Work_accident', 'salary' and 'department' one by one and build the model again, there is only a small change  in the AUC and other parameters 
#### * But if we remove any other variable after that and repeat the process, all the performance have a significant decrease


###The Problem Statement is : Why are the best and most experienced employees leaving prematurely ?

####So let's define who are the best and most experienced employees..        (above average)


####Last Evaluation >= 0.75
####time_spend_company >= 4
####number_project >= 5

###Now let us subset them
```{r , fig.width=4, fig.height=4}
##data1 <- data[-6,-8,-9,-10]
#Data <- data[,-(8:10),drop=FALSE]
Data <- subset( data, select = -c(6,8,9,10) ) 
gp <- Data[Data$last_evaluation >= 0.75 & data$number_project >= 5 & data$time_spend_company >= 4,]
#gp <- data[data$last_evaluation >= 0.75 & data$number_project >= 5 & data$time_spend_company >= 4,]
nrow(gp)
table(gp$left)
```

### Correlation Plot with the subsetted data
```{r , fig.width=4, fig.height=4}
library(corrplot)
gp1 <- gp[,1:6 ]
cor(gp[,1:6])
corrplot(cor(gp1[,1:6]), method="circle")
```



#Let's now repeat the entire process using Good people data

```{r , fig.width=4, fig.height=4}
library(caret)
set.seed(1234)
splitIndex <- createDataPartition(Data$left, p = .80,list = FALSE, times = 1)
trainSplit <- Data[ splitIndex,]
testSplit <- Data[-splitIndex,]
print(table(trainSplit$left))
print(table(testSplit$left))
```
#C5.0 tree
```{r , fig.width=4, fig.height=4}
### re-train and predict
ctrl <- trainControl(method = "cv", number = 5)
tbmodel <- train(as.factor(left) ~., data = trainSplit, method = "C5.0Tree", trControl = ctrl)
pred <- predict(tbmodel, testSplit)

### score prediction
confusionMatrix(testSplit$left, pred)
library(pROC)
auc1 <- roc(as.numeric(testSplit$left), as.numeric(pred))
print(auc1)
plot(auc1, ylim=c(0,1), print.thres=TRUE, main=paste('AUC:',round(auc1$auc[[1]],3)),col = 'blue')
```

###Now let's try other leftification models

### SVM
```{r, fig.width=4, fig.height=4}
ctrl <- trainControl(method = "cv", number = 5)
modelsvm <- train(as.factor(left) ~., data = trainSplit, method = "svmLinear", trControl = ctrl)

### predict
predsvm <- predict(modelsvm,testSplit)
summary(predsvm)

### score prediction using AUC
confusionMatrix(predsvm,testSplit$left)
library(pROC)
aucsvm <- roc(as.numeric(testSplit$left), as.numeric(predsvm),  ci=TRUE)
plot(aucsvm, ylim=c(0,1), print.thres=TRUE, main=paste('SVM AUC:',round(aucsvm$auc[[1]],3)),col = 'blue')
```


### Random Forest
```{r, fig.width=4, fig.height=4}
library(randomForest)
modelrf <- randomForest(as.factor(left) ~. , data = trainSplit)
importance(modelrf)

### predict
predrf <- predict(modelrf,testSplit)
summary(predrf)

### score prediction using AUC
confusionMatrix(predrf,testSplit$left)
library(pROC)
aucrf <- roc(as.numeric(testSplit$left), as.numeric(predrf),  ci=TRUE)
plot(aucrf, ylim=c(0,1), print.thres=TRUE, main=paste('Random Forest AUC:',round(aucrf$auc[[1]],3)),col = 'blue')
```


###decision tree
```{r}
library(rpart)
modeldt <- rpart(as.factor(left) ~. , data = trainSplit)
importance(modelrf)

### predict
preddt <- predict(modelrf,testSplit)
summary(preddt)

### score prediction using AUC
confusionMatrix(preddt,testSplit$left)
library(pROC)
aucdt <- roc(as.numeric(testSplit$left), as.numeric(predrf),  ci=TRUE)
plot(aucdt, ylim=c(0,1), print.thres=TRUE, main=paste('Decision Tree AUC:',round(aucrf$auc[[1]],3)),col = 'blue')
```

#### Naive bayes
```{r, fig.width=4, fig.height=4}

library(e1071)
library(rminer)
					
# 					
nbmodel <- naiveBayes(formula = as.factor(left) ~ ., data = trainSplit)	

predNB <- predict(nbmodel,testSplit, type = c("class", "raw"))					
# 				
summary(predNB)
# ### score prediction using AUC
confusionMatrix(predNB,testSplit$left)

library(pROC)
aucNB <- roc(as.numeric(testSplit$left), as.numeric(predrf),  ci=TRUE)
plot(aucNB, ylim=c(0,1), print.thres=TRUE, main=paste('Naive Bayes AUC:',round(aucrf$auc[[1]],3)),col = 'blue')
			
```




##Comparison of ROC Curves
```{r , fig.width=10, fig.height=4}
library(ggplot2)
plot(aucrf, ylim=c(0,1), main=paste('ROC Comparison : 
RF(red),C5.0(black),Decision Tree(Green),SVM(Yellow), Naive Bayes(brown)'),col = 'red')
par(new = TRUE)
plot(auc1)
par(new = TRUE)
plot(aucsvm,col = "yellow")
par(new = TRUE)
plot(aucdt,col = "green")
par(new = TRUE)
plot(aucNB,col = "brown")
```


#### Clearly, we find Random Forest is performing well. Therefore, we'll continue ahead with Random Forest

### Feature Engineering

```{r , fig.width=4, fig.height=4}

importance(modelrf)

```


####On observing the Mean Decrease Gini for each variable, we find variables 'promotion_last_5years', 'Work_accident', 'salary' and 'sales' are has the least value. So if we remove 'promotion_last_5years', 'Work_accident', 'salary' and 'sales' one by one and build the model again, there is only a small change  in the AUC and other parameters . But if we remove any other variable after that and repeat the process, all the performance have a significant decrease

# Actionable insights

The confusion matrix and the accuracy figures of the different model show that the predictive power is very similar and seems robust. About 95% accuracy and for a Kappa of 84%. We decide to keep the logistic regression model to lay out actionable insights. It's a very simple model and give the best results. 

Here is a plot that show the probability to leave of the employees and their performance. We need to focus on the top right. To do that we build a data table were we rank the probability to leave found in the logistic regression model and the performance, we therefore find the priority for the company. 

```{r, warning=F, fig.width=10}

# Keep some data to test again the final model
inTraining <- createDataPartition(Data$left, p = .75, list = FALSE)
training <- Data[ inTraining,]
testing  <- Data[-inTraining,]

# Estimate the drivers of attrition

modelrf <- randomForest(as.factor(left) ~. , data = training)
# Make predictions on the out-of-sample data

probaToLeave=predict(modelrf,newdata=testing,type="prob")
# Structure the prediction output in a table
predattrition = data.frame(probaToLeave)
# Add a column to the predattrition dataframe containing the performance
predattrition$performance=testing$last_evaluation
plot(predattrition$X1,predattrition$performance)
```

Here we display the first 300 employees that the company should retain. After grouping them per department we could email the different managers to tell them which valuable employees might leave soon.

```{r, warning=F, fig.width=10}
predattrition$priority=predattrition$performance*predattrition$X1
orderpredattrition=predattrition[order(predattrition$priority,decreasing = TRUE),]
orderpredattrition <- head(orderpredattrition, n=300)
datatable(orderpredattrition)
```

























